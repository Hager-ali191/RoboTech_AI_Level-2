{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "g44vnY041fIL",
        "n5p7YGAZ4aEX",
        "OaxcFX9T4k6F",
        "FFa0KKQC4pFQ",
        "HvI5H4ca5SxV",
        "P7W8N30t5OTK",
        "9cSrgn9o5JuJ",
        "RoayP-_b5Ez6",
        "cswzldaY4_5E",
        "MAfombW9bd1G",
        "S-bzFvGfbr6E",
        "6GCnPpl7bx53",
        "mCvOKHzEcGUS",
        "pyKIKbiHcL8b",
        "d7KC3xJmcSnh",
        "AsWca8drca0f",
        "gfCcMy45ceyh",
        "S1y8fzvt6xe7",
        "Atilw_EM5lrr",
        "85MytPQE6hIJ",
        "Y0veqoNN6qbp",
        "b5OSwcji6nWA",
        "kbgGxjLd6Uxy",
        "mwXsKWzW6JDE",
        "yAN1tFdf6aTb",
        "qMFXcIuQ6ApW",
        "3SU9jR8r50kv",
        "7iUW6PwJLhda",
        "wBxTLvWHLkzu",
        "poLuBKjmLqZR",
        "0dhPYuazXXW4",
        "MSnEzvgTY3sl",
        "YApsm6QN7r1L",
        "3x-yUWKzZ-tg",
        "o3vlHc_WZud7",
        "UdbF0kWESFT9",
        "mMk-8GYXSJLm",
        "HN9xcBZGSM5o",
        "nAvfZR1jS8Co",
        "k2sIhM5OSQN2",
        "TlWJ_UegSShv",
        "cwgF8KBiSW9k",
        "ycHRQuysSawM",
        "_ItObLM9TIEo",
        "AtCKNZDHSes3",
        "gWR-0UqFVlLd",
        "5-iUGK35WaMb",
        "8D8uklJMTyC6",
        "jA6DWkP4T1G-",
        "hk9rKNGZT3uM",
        "qqzSLSsBT-Wn",
        "cOg1ttXzUFGZ",
        "xXEhPhMpUPr-",
        "PV2r1n6DUSa3",
        "KX83aNYIVYl6"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **___ DataSet Description**"
      ],
      "metadata": {
        "id": "1ZQlLHF70pcE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Feature Name    | Description                                                                                     |\n",
        "| --------------- | ----------------------------------------------------------------------------------------------- |\n",
        "| **column1** | description. |\n",
        "\n"
      ],
      "metadata": {
        "id": "U2iHwAxH02XU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tg_MxaYy1bnn"
      },
      "source": [
        "# **Libraries**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBoHqduxqxXR"
      },
      "outputs": [],
      "source": [
        "# Pandas : Data Manipulation\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# NumPy : Math\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "\n",
        "# MatPlotLib\n",
        "import matplotlib\n",
        "from matplotlib import style\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "import plotly.figure_factory as ff\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from scipy.stats import skew\n",
        "\n",
        "\n",
        "# Missing Value Imputation\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "\n",
        "# handle imbalanced datasets\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "\n",
        "\n",
        "# additional preprocessing\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.preprocessing import PowerTransformer, QuantileTransformer\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "\n",
        "\n",
        "# Additional Metrics\n",
        "from sklearn.metrics import log_loss, balanced_accuracy_score\n",
        "from sklearn.metrics import precision_recall_curve, roc_curve, auc\n",
        "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_log_error\n",
        "\n",
        "\n",
        "# Additional Statistical & Utility Imports\n",
        "from scipy import stats\n",
        "from scipy.stats import norm, boxcox\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "# Spliting\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Scaling\n",
        "from sklearn.preprocessing import RobustScaler , MinMaxScaler , StandardScaler\n",
        "\n",
        "\n",
        "# Encoding\n",
        "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
        "# from category_encoders import OneHotEncoder,BinaryEncoder\n",
        "\n",
        "\n",
        "# Correlation\n",
        "# Feature Selection : Categorical\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "\n",
        "\n",
        "# Feature Selection : Numerical\n",
        "from sklearn.feature_selection import f_regression\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "\n",
        "# Feature Selection : Recursive Feature Elimination\n",
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "# Advanced Feature Selection\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.decomposition import PCA, TruncatedSVD\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "\n",
        "# Model Selection\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, KFold\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "\n",
        "# Classifiers\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
        "\n",
        "\n",
        "# regressors\n",
        "from sklearn.ensemble import RandomForestRegressor , RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeRegressor , DecisionTreeClassifier\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "\n",
        "# classifiers & regressors\n",
        "from sklearn.neighbors import KNeighborsClassifier , KNeighborsRegressor\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier, XGBRegressor\n",
        "import lightgbm as lgb\n",
        "from lightgbm import LGBMClassifier, LGBMRegressor\n",
        "# from catboost import CatBoostClassifier, CatBoostRegressor\n",
        "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
        "from sklearn.ensemble import AdaBoostClassifier, AdaBoostRegressor\n",
        "from sklearn.ensemble import BaggingClassifier, BaggingRegressor\n",
        "from sklearn.ensemble import VotingClassifier, VotingRegressor\n",
        "from sklearn.ensemble import StackingClassifier, StackingRegressor\n",
        "\n",
        "\n",
        "# clustering\n",
        "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
        "\n",
        "\n",
        "# classification\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score , accuracy_score\n",
        "from sklearn.metrics import confusion_matrix , classification_report\n",
        "\n",
        "\n",
        "# regression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "\n",
        "# unsupervised\n",
        "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score , adjusted_rand_score\n",
        "\n",
        "\n",
        "# handle overfitting\n",
        "from sklearn.linear_model import Ridge, Lasso\n",
        "\n",
        "\n",
        "# Utility for saving models\n",
        "import joblib\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g44vnY041fIL"
      },
      "source": [
        "# **Class**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Information**"
      ],
      "metadata": {
        "id": "n5p7YGAZ4aEX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcHd-I2biXwH"
      },
      "outputs": [],
      "source": [
        "class MachineLearning:\n",
        "\n",
        "  def data_information (self , data_frame):\n",
        "\n",
        "    \"\"\"\n",
        "        Steps of understanding data to build the model ?\n",
        "\n",
        "          Analysis :\n",
        "            - plots of data frame for categorical & numerical\n",
        "            - Some Math -> describe()\n",
        "\n",
        "          Preprocessing :\n",
        "            - Names of columns\n",
        "            - Data types -> info() or here\n",
        "            - nulls\n",
        "            - duplicates\n",
        "            - unique (num & values)\n",
        "            - mean & median & mode : -> describe()\n",
        "            - outliers -> box plot & math ( describe() )\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "        Just to know the information of each column.\n",
        "        I get each name of it.\n",
        "        Also each data type.\n",
        "    \"\"\"\n",
        "    name_of_each_column = [col for col in data_frame]\n",
        "    data_types_of_each_column = [data_frame[col].dtype for col in data_frame.columns]\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "        Number of null values in each column is not enough to know if it is huge or not.\n",
        "        I need to calculate the percentage of it based on length of data frame to make it clear.\n",
        "    \"\"\"\n",
        "    null_values_of_each_column = [data_frame[col].isnull().sum() for col in data_frame.columns]\n",
        "    percentage_of_null_values_of_each_column = [data_frame[col].isnull().sum() / len(data_frame) * 100 for col in data_frame.columns]\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "        Unique values make me know :\n",
        "\n",
        "          - What are the exact values of each column ?\n",
        "          - Column is categorical or numerical ?\n",
        "\n",
        "    \"\"\"\n",
        "    num_of_unique_values_of_each_column = [data_frame[col].nunique() for col in data_frame.columns]\n",
        "    unique_values_of_each_column = [data_frame[col].unique() for col in data_frame.columns]\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "        What are the num of duplicates in data frame ?\n",
        "    \"\"\"\n",
        "    duplicates = data_frame.duplicated().sum()\n",
        "\n",
        "\n",
        "\n",
        "    information_of_data = pd.DataFrame(\n",
        "        {\n",
        "            'Names' : name_of_each_column ,\n",
        "            'Values' : unique_values_of_each_column ,\n",
        "            'Data Type' : data_types_of_each_column ,\n",
        "            'Unique Num' : num_of_unique_values_of_each_column ,\n",
        "            'Null Num' : null_values_of_each_column ,\n",
        "            'Null Percentage' : percentage_of_null_values_of_each_column ,\n",
        "            'Duplicates' : duplicates\n",
        "        }\n",
        "    )\n",
        "\n",
        "    return information_of_data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Plots**"
      ],
      "metadata": {
        "id": "OaxcFX9T4k6F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Categorical plots: count, bar, box, violin, strip, swarm\n",
        "\n",
        "Distribution plots: hist, kde, violin\n",
        "\n",
        "Relational plots: scatter, line, joint, pair\n",
        "\n",
        "Matrix plots: heatmap"
      ],
      "metadata": {
        "id": "Z958JOsicrLS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Bar Plot**"
      ],
      "metadata": {
        "id": "FFa0KKQC4pFQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  def bar_plot(self , column , data_frame):\n",
        "    sns.set_style(\"whitegrid\")\n",
        "    surviver_counts = data_frame[column].value_counts(normalize=True)*100\n",
        "\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    ax = sns.barplot(x=surviver_counts.index, y=data_frame[column].value_counts(), palette=\"rocket\")\n",
        "\n",
        "    plt.title(f\"Percentage of {column} and Non-{column}\", fontsize=14, fontweight='bold')\n",
        "    plt.xlabel(f\"{column} Status\", fontsize=12, fontweight='bold')\n",
        "    plt.ylabel(\"Count\", fontsize=12, fontweight='bold')\n",
        "\n",
        "    for p, percentage in zip(ax.patches, surviver_counts.values):\n",
        "      ax.annotate(f'{percentage:.1f}%',\n",
        "                  (p.get_x() + p.get_width() / 2, p.get_height()),\n",
        "                  ha='center', va='bottom',\n",
        "                  fontsize=12, fontweight='bold', color='black')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "_zVoY8lW4ngt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Histogram**"
      ],
      "metadata": {
        "id": "HvI5H4ca5SxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  def histogram_plot(self , column , data_frame):\n",
        "    sns.set_style(\"whitegrid\")\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    skewness = skew(data_frame[column], nan_policy=\"omit\")\n",
        "    sns.histplot(data_frame[column], bins=50, kde=True, color=\"navy\", edgecolor=\"black\")\n",
        "\n",
        "    plt.xlabel(column, fontsize=14, fontweight='bold')\n",
        "    plt.ylabel(\"Frequency\", fontsize=14, fontweight='bold')\n",
        "    plt.title(f\"Distribution of {column}\", fontsize=16, fontweight='bold')\n",
        "\n",
        "    plt.text(\n",
        "        x=data_frame[column].max() * 0.7,\n",
        "        y=plt.gca().get_ylim()[1] * 0.7,\n",
        "        s=f\"Skewness: {skewness:.2f}\",\n",
        "        fontsize=15, fontweight=\"bold\", color=\"navy\"\n",
        "    )\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "BHd0pRR65V6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Strip Plot**"
      ],
      "metadata": {
        "id": "P7W8N30t5OTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  def strip_plot(self , column_x , column_y , data_frame):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.stripplot(x=data_frame[column_x], y=data_frame[column_y], jitter=True, alpha=0.7, palette=[\"#1f77b4\", \"#ff7f0e\"])\n",
        "    plt.xlabel(column_x, fontsize=14, fontweight=\"bold\")\n",
        "    plt.ylabel(column_y, fontsize=14, fontweight=\"bold\")\n",
        "    plt.title(f\"Strip Plot of {column_y} by {column_x}\", fontsize=16, fontweight=\"bold\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Fq_IZYE25RLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Pie Plot**"
      ],
      "metadata": {
        "id": "9cSrgn9o5JuJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  def pie_chart(self , column , data_frame):\n",
        "    satisfaction_counts = data_frame[column].value_counts()\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.pie(satisfaction_counts,\n",
        "            labels=satisfaction_counts.index,\n",
        "            autopct='%1.1f%%',\n",
        "            startangle=90,\n",
        "            colors=plt.cm.Dark2.colors)\n",
        "\n",
        "    plt.title(f\"Distribution of {column}\")\n",
        "    plt.axis('equal')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "SRSsk4y65MVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Box Plot**"
      ],
      "metadata": {
        "id": "RoayP-_b5Ez6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  def box_plot(self , column_x , column_y , data_frame):\n",
        "    plt.figure(figsize=(10,5))\n",
        "    sns.boxplot(x = column_x, y = column_y, data = data_frame, palette=\"rocket\")\n",
        "\n",
        "    plt.xlabel(column_x)\n",
        "    plt.ylabel(column_y)\n",
        "    plt.title(f'Box Plot of {column_y} by {column_x}')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "kKuwjk5C5Hks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Count Plot**"
      ],
      "metadata": {
        "id": "cswzldaY4_5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  def count_plot(self , column , hue , data_frame):\n",
        "    ax = sns.countplot(x = column , data=data_frame, palette='rocket',hue=hue)\n",
        "\n",
        "    for p in ax.patches:\n",
        "        height = p.get_height()\n",
        "        if height > 0:\n",
        "            ax.text(p.get_x() + p.get_width() / 2, height,\n",
        "                    f'{height/len(data_frame)*100:.2f}%', ha='center', va='bottom', fontsize=10, color='black')\n",
        "\n",
        "    plt.title(f'Count of {column} with {hue} Status')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "eLB2Y6_G5CHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Scatter Plot**"
      ],
      "metadata": {
        "id": "MAfombW9bd1G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "   def scatter_plot(self, x, y, hue, data_frame):\n",
        "        ax = sns.scatterplot(x=x, y=y, data=data_frame, hue=hue, palette=self.palette)\n",
        "        plt.title(f'Scatter plot of {x} vs {y} by {hue}')\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "ldO_z3N2bha-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Heatmap Plot**"
      ],
      "metadata": {
        "id": "S-bzFvGfbr6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    def heatmap(self, data_frame):\n",
        "        corr = data_frame.corr()\n",
        "        ax = sns.heatmap(corr, annot=True, cmap=\"rocket\", fmt=\".2f\")\n",
        "        plt.title(\"Correlation Heatmap\")\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "O69mTYUvbuSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Violin Plot**"
      ],
      "metadata": {
        "id": "6GCnPpl7bx53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  def violin_plot(self, x, y, hue, data_frame):\n",
        "        ax = sns.violinplot(x=x, y=y, data=data_frame, hue=hue, palette=self.palette, split=True)\n",
        "        plt.title(f'Violin plot of {y} across {x} grouped by {hue}')\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "l4l7LXv3b1nY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Swarm Plot**"
      ],
      "metadata": {
        "id": "mCvOKHzEcGUS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    def swarm_plot(self, x, y, hue, data_frame):\n",
        "        sns.swarmplot(x=x, y=y, data=data_frame, hue=hue, palette=self.palette, dodge=True)\n",
        "        plt.title(f'Swarm plot of {y} across {x} grouped by {hue}')\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "FqjdM1WTcFpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **KDE Plot**"
      ],
      "metadata": {
        "id": "pyKIKbiHcL8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    def kde_plot(self, column, hue, data_frame):\n",
        "        sns.kdeplot(data=data_frame, x=column, hue=hue, fill=True, palette=self.palette)\n",
        "        plt.title(f'KDE plot of {column} by {hue}')\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "iNSQY5TrcP8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Line Plot**"
      ],
      "metadata": {
        "id": "d7KC3xJmcSnh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    def line_plot(self, x, y, hue, data_frame):\n",
        "        sns.lineplot(x=x, y=y, data=data_frame, hue=hue, palette=self.palette)\n",
        "        plt.title(f'Line plot of {y} vs {x} by {hue}')\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "JuMWZ7k2cVDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Pair Plot**"
      ],
      "metadata": {
        "id": "AsWca8drca0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "   def pair_plot(self, data_frame, hue=None):\n",
        "        sns.pairplot(data_frame, hue=hue, palette=self.palette)\n",
        "        plt.suptitle(\"Pairplot of features\", y=1.02)\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "ot7yCEUUcdC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Joint Plot**"
      ],
      "metadata": {
        "id": "gfCcMy45ceyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    def joint_plot(self, x, y, data_frame, kind=\"scatter\"):\n",
        "        sns.jointplot(x=x, y=y, data=data_frame, kind=kind, palette=self.palette)\n",
        "        plt.suptitle(f'Joint plot of {x} vs {y}', y=1.02)\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "STKRTribch2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Preprocessing**"
      ],
      "metadata": {
        "id": "S1y8fzvt6xe7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Null**"
      ],
      "metadata": {
        "id": "Atilw_EM5lrr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  def handle_null_values(self , handling_type , columns , data_frame):\n",
        "\n",
        "    # handling_type -> mode , mean (not prefered) , median , knn imputer\n",
        "\n",
        "    if handling_type == 'mode' :\n",
        "\n",
        "      for col in columns:\n",
        "        # replace it with the most frequent value :\n",
        "        data_frame[col] = data_frame[col].fillna( data_frame[col].mode()[0] )\n",
        "\n",
        "    elif handling_type == 'knn imputer' :\n",
        "\n",
        "      for col in columns:\n",
        "        # replaces it with the previous value, and if it can't find it, then with the next one.\n",
        "        data_frame[col] = data_frame[col].fillna(method='ffill').fillna(method='bfill')\n",
        "\n",
        "\n",
        "    elif handling_type == 'median' :\n",
        "\n",
        "      for col in columns :\n",
        "        # replace it with the median because if the data is not normally distributed, the mean will be a problem.\n",
        "        data_frame[col] = data_frame[col].fillna(data_frame[col].median())\n",
        "\n",
        "    else :\n",
        "      print(\"Invalid Value\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wPvKl5D95oZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Outliers**"
      ],
      "metadata": {
        "id": "85MytPQE6hIJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Checking**"
      ],
      "metadata": {
        "id": "Y0veqoNN6qbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  def check_outliers(self , columns , data_frame ,whis = 1.5):\n",
        "\n",
        "    fig, axes = plt.subplots(3, 3, figsize=(20, 5 * 3))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for i, col in enumerate(columns):\n",
        "        sns.boxplot(data=data_frame, y=col, ax=axes[i], palette='magma',whis=whis)\n",
        "        axes[i].set_title(f'Boxplot of {col}', fontsize=12)\n",
        "        axes[i].set_xlabel('')\n",
        "        axes[i].set_ylabel(col)\n",
        "\n",
        "    for j in range(i + 1, len(axes)):\n",
        "        fig.delaxes(axes[j])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "3lt4GHwW6slI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Handling**"
      ],
      "metadata": {
        "id": "b5OSwcji6nWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  def handle_outliers(self , data_frame , column, upper_value = 1.5 , lower_value = 1.5 , handle = 'no'):\n",
        "\n",
        "      for col in column:\n",
        "\n",
        "          Q1=data_frame[col].quantile(0.25)\n",
        "          Q3=data_frame[col].quantile(0.75)\n",
        "          IQR=Q3-Q1\n",
        "\n",
        "          lower_bound=Q1-(lower_value*IQR)\n",
        "          upper_bound=Q3+(upper_value*IQR)\n",
        "\n",
        "          outliers_mask_lower = (data_frame['Age'] < lower_bound)\n",
        "          outliers_mask_upper = (data_frame['Age'] > upper_bound)\n",
        "          outliers_count_lower = outliers_mask_lower.sum()\n",
        "          outliers_count_upper = outliers_mask_upper.sum()\n",
        "          print(f\"Number of lower Outliers in {col} : {outliers_count_lower}\")\n",
        "          print(f\"Number of upper Outliers in {col} : {outliers_count_upper}\")\n",
        "\n",
        "          if handle == 'yes' :\n",
        "            data_frame[col]=np.where(data_frame[col]<lower_bound,lower_bound,data_frame[col])\n",
        "            data_frame[col]=np.where(data_frame[col]>upper_bound,upper_bound,data_frame[col])\n",
        "\n",
        "      return data_frame"
      ],
      "metadata": {
        "id": "8psWzoWv6jq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Scaling**"
      ],
      "metadata": {
        "id": "kbgGxjLd6Uxy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  def scaling_data(self , scaler_type , data_frame , features_train , features_test , columns_list):\n",
        "\n",
        "    if scaler_type == 'standard scaler':\n",
        "      # Standard Scalar :\n",
        "      standard_scaler = StandardScaler()\n",
        "      features_train[columns_list] = standard_scaler.fit_transform(features_train[columns_list])\n",
        "      features_test[columns_list] = standard_scaler.transform(features_test[columns_list])\n",
        "\n",
        "\n",
        "    elif scaler_type == 'min max scaler':\n",
        "      # Min Max Scalar :\n",
        "      min_max_scaler = MinMaxScaler()\n",
        "      features_train[columns_list] = min_max_scaler.fit_transform(features_train[columns_list])\n",
        "      features_test[columns_list] = min_max_scaler.transform(features_test[columns_list])\n",
        "\n",
        "\n",
        "    elif scaler_type == 'robust scaler':\n",
        "      # Robust Scaler :\n",
        "      robust_scaler = RobustScaler()\n",
        "      features_train[columns_list] = robust_scaler.fit_transform(features_train[columns_list])\n",
        "      features_test[columns_list] = robust_scaler.transform(features_test[columns_list])\n",
        "\n",
        "    else:\n",
        "      print(\"There is no scaler type with this name.\")\n",
        "\n",
        "\n",
        "    return features_train , features_test"
      ],
      "metadata": {
        "id": "b0x9l7-e6X0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Encoding**"
      ],
      "metadata": {
        "id": "mwXsKWzW6JDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  def encoding_data(self , encoding_type , features_train , features_test , data_frame , columns_list):\n",
        "\n",
        "    if encoding_type == 'label':\n",
        "\n",
        "      label_encoding = LabelEncoder()\n",
        "      features_train=label_encoding.fit_transform(features_train)\n",
        "      features_test=label_encoding.transform(features_test)\n",
        "\n",
        "    elif encoding_type == 'ordinal':\n",
        "\n",
        "      # handling unseen data\n",
        "      all_categories = {}\n",
        "      for col in columns_list:\n",
        "          train_cats = features_train[col].unique()\n",
        "          all_categories[col] = sorted(set(train_cats))\n",
        "\n",
        "      ordinal_encoder = OrdinalEncoder(\n",
        "          categories=[all_categories[col] for col in columns_list],\n",
        "          handle_unknown='use_encoded_value',\n",
        "          unknown_value=len(all_categories[col])\n",
        "        )\n",
        "\n",
        "      features_train[columns_list] = ordinal_encoder.fit_transform(features_train[columns_list])\n",
        "      features_test[columns_list] = ordinal_encoder.transform(features_test[columns_list])\n",
        "\n",
        "      return features_train , features_test\n",
        "\n",
        "    elif encoding_type == 'onehot':\n",
        "\n",
        "      data_frame = pd.get_dummies(data_frame, columns = columns_list)\n",
        "      return data_frame"
      ],
      "metadata": {
        "id": "-Aj7ltUp6Q4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Spliting**"
      ],
      "metadata": {
        "id": "yAN1tFdf6aTb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  def spliting_data(self , data_frame , label , test_size = 0.2 , random_state = 42):\n",
        "\n",
        "    features = data_frame.drop([label],axis=1)\n",
        "    target =data_frame[label]\n",
        "    # random_state = 42 -> to make the split the same every time\n",
        "    features_train , features_test , target_train , target_test = train_test_split(features, target, test_size=test_size, random_state=random_state)\n",
        "\n",
        "    return features_train , features_test , target_train , target_test\n",
        "\n"
      ],
      "metadata": {
        "id": "Seefe42E6c6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Correlation**"
      ],
      "metadata": {
        "id": "qMFXcIuQ6ApW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  def correlation(self , features_train , target_train , data_frame , numerical_columns , categorical_columns):\n",
        "\n",
        "    # Numerical : anova\n",
        "    x = features_train[numerical_columns]\n",
        "    y = target_train\n",
        "\n",
        "    f_values, p_values = f_classif(x, y)\n",
        "\n",
        "    numerical_anova_data_frame = pd.DataFrame({\n",
        "        'Feature': numerical_columns,\n",
        "        'F-Score': f_values,\n",
        "        'P-Value': p_values\n",
        "    }).sort_values(by='F-Score', ascending=False)\n",
        "\n",
        "\n",
        "    # # Categorical : chi2\n",
        "    x=features_train[categorical_columns]\n",
        "    y=target_train\n",
        "\n",
        "    chi2_selector = SelectKBest(score_func=chi2, k='all')\n",
        "    chi2_selector.fit(x, y)\n",
        "\n",
        "    categorical_chi2_data_frame = pd.DataFrame({\n",
        "        'Feature': x.columns,\n",
        "        'Chi2 Score': chi2_selector.scores_,\n",
        "        'P-Value': chi2_selector.pvalues_\n",
        "    }).sort_values(by='Chi2 Score', ascending=False)\n",
        "\n",
        "    return numerical_anova_data_frame , categorical_chi2_data_frame"
      ],
      "metadata": {
        "id": "iSz6O7CX6Fea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Grid Search**"
      ],
      "metadata": {
        "id": "3SU9jR8r50kv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  def best_parameters(self , text , model_type , params , model , x_train, x_test, y_train, y_test):\n",
        "\n",
        "    result = {}\n",
        "\n",
        "    # grid Search : to find the best hyperparameters\n",
        "    grid = GridSearchCV(\n",
        "      # random_state = 42 -> same initial weights for comparsion\n",
        "        estimator = model,\n",
        "        # what parameters to try\n",
        "        param_grid = params,\n",
        "        # cross validation\n",
        "        cv=5,\n",
        "        # get the accuracy\n",
        "        scoring='accuracy',\n",
        "        # run on cpu\n",
        "        n_jobs=-1,\n",
        "\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    grid.fit(x_train, y_train)\n",
        "\n",
        "    # best_estimator_ : returns the model with the best hyperparameters found during grid search\n",
        "    best = grid.best_estimator_\n",
        "    result[f'Best {text} Model'] = best\n",
        "\n",
        "    y_train_pred = best.predict(x_train)\n",
        "\n",
        "    y_test_pred = best.predict(x_test)\n",
        "\n",
        "    if model_type == 'classification':\n",
        "      # calculate metrics -> accuracy , precision , recall , f1 , auc\n",
        "      metrics_train = {\n",
        "          # accuracy : (TP + TN) / (TP + TN + FP + FN)\n",
        "          'accuracy': accuracy_score(y_train, y_train_pred),\n",
        "          # precision : TP / (TP + FP)\n",
        "          'precision': precision_score(y_train, y_train_pred),\n",
        "          # recall : TP / (TP + FN)\n",
        "          'recall': recall_score(y_train, y_train_pred),\n",
        "          # f1 score : 2 * (precision * recall) / (precision + recall)\n",
        "          'f1': f1_score(y_train, y_train_pred),\n",
        "          # auc : area under the roc curve\n",
        "          'auc': roc_auc_score(y_train, y_train_pred),\n",
        "          # best parameters from grid search\n",
        "          'best_params': grid.best_params_\n",
        "      }\n",
        "      metrics_test = {\n",
        "          'accuracy': accuracy_score(y_test, y_test_pred),\n",
        "          'precision': precision_score(y_test, y_test_pred),\n",
        "          'recall': recall_score(y_test, y_test_pred),\n",
        "          'f1': f1_score(y_test, y_test_pred),\n",
        "          'auc': roc_auc_score(y_test, y_test_pred),\n",
        "          'best_params': grid.best_params_\n",
        "      }\n",
        "      print(f\"Best {text}\")\n",
        "      print(f\"Best Parameters: {grid.best_params_}\")\n",
        "      print(f\"Silhouette Score: {metrics_train['accuracy']:.4f}\")\n",
        "      print(f\"Test Accuracy: {metrics_test['accuracy']:.4f}\")\n",
        "\n",
        "\n",
        "    elif model_type == 'regression':\n",
        "      metrics_train = {\n",
        "          # RÂ² : proportion of variance explained by the model\n",
        "          'r2': r2_score(y_train, y_train_pred),\n",
        "          # MAE : mean absolute error\n",
        "          'mae': mean_absolute_error(y_train, y_train_pred),\n",
        "          # MSE : mean squared error\n",
        "          'mse': mean_squared_error(y_train, y_train_pred),\n",
        "          # RMSE : root mean squared error\n",
        "          'rmse': np.sqrt(mean_squared_error(y_train, y_train_pred)),\n",
        "          # best parameters from grid search\n",
        "          'best_params': grid.best_params_\n",
        "      }\n",
        "      metrics_test = {\n",
        "          'r2': r2_score(y_test, y_test_pred),\n",
        "          'mae': mean_absolute_error(y_test, y_test_pred),\n",
        "          'mse': mean_squared_error(y_test, y_test_pred),\n",
        "          'rmse': np.sqrt(mean_squared_error(y_test, y_test_pred)),\n",
        "          'best_params': grid.best_params_\n",
        "      }\n",
        "      print(f\"Best {text}\")\n",
        "      print(f\"Best Parameters: {grid.best_params_}\")\n",
        "      print(f\"Silhouette Score: {metrics_train['r2']:.4f}\")\n",
        "      print(f\"Test Accuracy: {metrics_test['r2']:.4f}\")\n",
        "\n",
        "\n",
        "    elif model_type == 'unsupervised':\n",
        "      # calculate metrics -> silhouette , davies-bouldin , calinski-harabasz\n",
        "      metrics_train = {\n",
        "          # silhouette : cohesion vs separation (-1 to 1, higher is better)\n",
        "          'silhouette': silhouette_score(x_train, y_train_pred),\n",
        "          # davies-bouldin : average similarity between clusters (lower is better)\n",
        "          'davies_bouldin': davies_bouldin_score(x_train, y_train_pred),\n",
        "          # calinski-harabasz : ratio of between-cluster dispersion to within-cluster dispersion (higher is better)\n",
        "          'calinski_harabasz': calinski_harabasz_score(x_train, y_train_pred),\n",
        "          # best parameters from grid search\n",
        "          'best_params': grid.best_params_\n",
        "      }\n",
        "      metrics_test = {\n",
        "          'silhouette': silhouette_score(x_test, y_test_pred),\n",
        "          'davies_bouldin': davies_bouldin_score(x_test, y_test_pred),\n",
        "          'calinski_harabasz': calinski_harabasz_score(x_test, y_test_pred),\n",
        "          'best_params': grid.best_params_\n",
        "      }\n",
        "      print(f\"Best {text}\")\n",
        "      print(f\"Best Parameters: {grid.best_params_}\")\n",
        "      print(f\"Silhouette Score: {metrics_train['silhouette']:.4f}\")\n",
        "      print(f\"Test Accuracy: {metrics_test['silhouette']:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "    result[f'{text} Train Metrics'] = metrics_train\n",
        "    result[f'{text} Test Metrics'] = metrics_test\n",
        "\n",
        "    return result\n",
        "\n"
      ],
      "metadata": {
        "id": "VQ9_Vd3w524Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Parameters Guide**"
      ],
      "metadata": {
        "id": "oXZ41MCG82Ge"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Regression**"
      ],
      "metadata": {
        "id": "7iUW6PwJLhda"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ridge = {\n",
        "    'alpha': [0.01, 0.1, 1, 10],\n",
        "    # 'solver': ['auto', 'svd', 'cholesky'],\n",
        "}"
      ],
      "metadata": {
        "id": "87mWIxGoA9Ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lasso = {\n",
        "    'alpha': [0.01, 0.1, 1, 10],\n",
        "    # 'max_iter': [1000, 2000],\n",
        "}"
      ],
      "metadata": {
        "id": "ClctTIuYA-zo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Classification**"
      ],
      "metadata": {
        "id": "wBxTLvWHLkzu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logistic_regression = {\n",
        "    'C': [0.01, 0.1, 1, 10],   # Regularization strength (smaller = stronger regularization)\n",
        "    'penalty': ['l1', 'l2', 'elasticnet', 'none'], # l1 = Lasso (feature selection), l2 = Ridge (spread error)\n",
        "    'solver': ['saga' , 'liblinear'],  # saga supports l1, l2, elasticnet\n",
        "    # 'class_weight': [None, 'balanced'], # Handle class imbalance\n",
        "    # 'max_iter': [100, 200, 500],  # less critical\n",
        "}"
      ],
      "metadata": {
        "id": "HHbbC-xG7bHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xg_boost = {\n",
        "    'n_estimators': [100, 200, 500],  # Number of boosting rounds\n",
        "    'learning_rate': [0.01, 0.1, 0.2], # Step size shrinkage\n",
        "    'max_depth': [3, 5, 7],           # Tree depth\n",
        "    'subsample': [0.8, 1.0],          # Fraction of samples\n",
        "    'colsample_bytree': [0.8, 1.0],   # Fraction of features per tree\n",
        "    'gamma': [0, 0.1, 0.5]            # Minimum loss reduction for split\n",
        "}"
      ],
      "metadata": {
        "id": "Qz9vOHSA-HCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "naive_bayes_or_GaussianNB = {\n",
        "    'var_smoothing': [1e-09, 1e-08, 1e-07] # Stability parameter to avoid division by zero\n",
        "}"
      ],
      "metadata": {
        "id": "RoOWaT5I-ZX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Supervised**"
      ],
      "metadata": {
        "id": "poLuBKjmLqZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "support_vector_machine = {\n",
        "    'C': [0.1, 1, 10],                # Regularization strength\n",
        "    'kernel': ['linear', 'rbf', 'poly'], # Kernel type\n",
        "    'gamma': ['scale', 'auto'],       # Kernel coefficient (rbf/poly)\n",
        "    # 'class_weight': [None, 'balanced'] # Handle imbalance\n",
        "    # 'degree': [2, 3, 4]\n",
        "}"
      ],
      "metadata": {
        "id": "yREr4-dw8yY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decision_tree = {\n",
        "    'criterion': ['gini', 'entropy'], # Split quality measure\n",
        "    'max_depth': [None, 5, 10, 20],   # Limit depth to avoid overfitting\n",
        "    'min_samples_split': [2, 5, 10],  # Minimum samples to split a node\n",
        "    'min_samples_leaf': [1, 2, 4],    # Minimum samples per leaf\n",
        "    'class_weight': [None, 'balanced'] # Handle imbalance\n",
        "}"
      ],
      "metadata": {
        "id": "IyjDx-M19zhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_forest = {\n",
        "    'n_estimators': [100, 200, 500],  # Number of trees\n",
        "    'criterion': ['gini', 'entropy'], # Split quality measure\n",
        "    'max_depth': [None, 10, 20],      # Tree depth\n",
        "    'min_samples_split': [2, 5, 10],  # Minimum samples to split\n",
        "    'min_samples_leaf': [1, 2, 4],    # Minimum samples per leaf\n",
        "    # 'bootstrap': [True, False],       # Whether to use bootstrapped samples\n",
        "    # 'class_weight': [None, 'balanced'] # Handle imbalance\n",
        "}"
      ],
      "metadata": {
        "id": "FLBri8AQ92Lx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k_nearest_neighbors  = {\n",
        "    'n_neighbors': [3, 5, 7, 11],     # Number of neighbors\n",
        "    'weights': ['uniform', 'distance'], # Uniform = equal weight, distance = closer neighbors matter more\n",
        "    'metric': ['euclidean', 'manhattan', 'minkowski'] # Distance metric\n",
        "}"
      ],
      "metadata": {
        "id": "24wfSYtg97us"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gradient_boosting = {\n",
        "    'n_estimators': [100, 200, 500],  # Number of boosting stages\n",
        "    'learning_rate': [0.01, 0.1, 0.2], # Shrinks contribution of each tree\n",
        "    'max_depth': [3, 5, 7],           # Depth of individual trees\n",
        "    'min_samples_split': [2, 5, 10],  # Minimum samples to split\n",
        "    'min_samples_leaf': [1, 2, 4]     # Minimum samples per leaf\n",
        "    # 'subsample': [0.8, 1.0]          # Fraction of samples used per tree\n",
        "}"
      ],
      "metadata": {
        "id": "M-mlpGkx-Amo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Unsupervised**"
      ],
      "metadata": {
        "id": "xoi7UB6DL1MC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = {\n",
        "    'n_clusters': [2, 3, 5, 10],\n",
        "    'init': ['k-means++', 'random'],\n",
        "    'n_init': [10, 20],\n",
        "    # 'max_iter': [300, 500],\n",
        "}"
      ],
      "metadata": {
        "id": "K42mOrNhLR-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agglomerative_clustering = {\n",
        "    'n_clusters': [2, 3, 5, 10],\n",
        "    'linkage': ['ward', 'complete', 'average'],\n",
        "    # 'affinity': ['euclidean', 'manhattan'],\n",
        "}"
      ],
      "metadata": {
        "id": "g3ag8VcALYsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dbscan = {\n",
        "    'eps': [0.3, 0.5, 1.0],\n",
        "    'min_samples': [5, 10],\n",
        "    # 'metric': ['euclidean', 'manhattan'],\n",
        "}"
      ],
      "metadata": {
        "id": "e-YrBdygLaeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Train & Test**"
      ],
      "metadata": {
        "id": "0dhPYuazXXW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  def train_test_evaluate(self , caler_type , x_train , x_test , y_train , y_test , model):\n",
        "\n",
        "    model.fit(x_train, y_train)\n",
        "    y_pred = model.predict(x_test)\n",
        "    y_pred_train = model.predict(x_train)\n",
        "    print(f\"{scaler_type} Scaler\")\n",
        "    print(\"Train Accuracy:\", accuracy_score(y_train, y_pred_train))\n",
        "    print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "js22jzg0XgtS"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Evaluation**"
      ],
      "metadata": {
        "id": "MSnEzvgTY3sl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_classification(self , y_test, y_pred, labels=None):\n",
        "    # Metrics\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred, average=\"weighted\")\n",
        "    rec = recall_score(y_test, y_pred, average=\"weighted\")\n",
        "    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
        "\n",
        "    print(f\"Accuracy: {acc:.4f}\")\n",
        "    print(f\"Precision: {prec:.4f}\")\n",
        "    print(f\"Recall: {rec:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    plt.figure(figsize=(6,4))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "                xticklabels=labels, yticklabels=labels)\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "kZFSxe5XaC4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_regression(self , y_test, y_pred):\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"MAE: {mae:.4f}\")\n",
        "    print(f\"MSE: {mse:.4f}\")\n",
        "    print(f\"RMSE: {rmse:.4f}\")\n",
        "    print(f\"RÂ² Score: {r2:.4f}\")\n"
      ],
      "metadata": {
        "id": "gV5Sd81zZ_LQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_clustering(self , X, labels, true_labels=None):\n",
        "    # Internal metrics (no ground truth needed)\n",
        "    sil = silhouette_score(X, labels)\n",
        "    db = davies_bouldin_score(X, labels)\n",
        "\n",
        "    print(f\"Silhouette Score: {sil:.4f}\")\n",
        "    print(f\"Davies-Bouldin Index: {db:.4f}\")\n",
        "\n",
        "    # External metric (only if true labels are available)\n",
        "    if true_labels is not None:\n",
        "        ari = adjusted_rand_score(true_labels, labels)\n",
        "        print(f\"Adjusted Rand Index (vs true labels): {ari:.4f}\")"
      ],
      "metadata": {
        "id": "wwxZSjWPZ7RD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Code**"
      ],
      "metadata": {
        "id": "9IFMxNFNP4BO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YApsm6QN7r1L"
      },
      "source": [
        "## **Loading Data**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNaTO6Jr1avP"
      },
      "outputs": [],
      "source": [
        "data_frame = pd.read_csv('file.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEidf4odMTbi"
      },
      "outputs": [],
      "source": [
        "algorithm = MachineLearning()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3x-yUWKzZ-tg"
      },
      "source": [
        "## **Information**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lcyiyhm-Xx2v"
      },
      "outputs": [],
      "source": [
        "data_frame.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKIryCiIX0SE"
      },
      "outputs": [],
      "source": [
        "data_frame.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbY4h3mCMR2N"
      },
      "outputs": [],
      "source": [
        "algorithm.data_information(data_frame)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdK2FTR0Sn5w"
      },
      "outputs": [],
      "source": [
        "numerical_columns = [ ]\n",
        "categorical_columns = [ ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5Uglehhaqi2"
      },
      "outputs": [],
      "source": [
        "print(data_frame.isnull().sum().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmfLoU2YXl0d"
      },
      "outputs": [],
      "source": [
        "data_frame.describe().T.style.bar(subset=['mean'], color='#FFA07A').background_gradient(\n",
        "    subset=['std', '50%', 'max'], cmap='Blues').set_properties(\n",
        "        **{'font-size': '12pt', 'border': '1.5px solid black'}).set_caption(\"ð Summary Statistics of the Dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhzeorwSgUKP"
      },
      "outputs": [],
      "source": [
        "algorithm.data_information(data_frame)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3vlHc_WZud7"
      },
      "source": [
        "### **Data Overview Insights**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfIt_ldFVMCe"
      },
      "source": [
        "1. Shape of data set is - rows & - columns\n",
        "\n",
        "2. Nulls are - null values\n",
        "\n",
        "3. there are _ integer columns + _ float columns + _ object\n",
        "\n",
        "4. Outliers :\n",
        "\n",
        "   - _ Column has a miximum value of _ , much higher than the 75th percentile (30) , but it is _ a problem.\n",
        "\n",
        "6. Target Variable: _\n",
        "   - _% of _ _ (mean = _)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Analysis**"
      ],
      "metadata": {
        "id": "UdbF0kWESFT9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wG1smIGZSLuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Preprocessing**"
      ],
      "metadata": {
        "id": "mMk-8GYXSJLm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Irrelevant Columns**"
      ],
      "metadata": {
        "id": "HN9xcBZGSM5o"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qW1DMv12SMWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Data type inspection**"
      ],
      "metadata": {
        "id": "nAvfZR1jS8Co"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wE9ieSsbS_Kv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Nulls**"
      ],
      "metadata": {
        "id": "k2sIhM5OSQN2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B1d85QyQSSKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Outliers**"
      ],
      "metadata": {
        "id": "TlWJ_UegSShv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cFRTYxYWSVtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Feature Engineering**"
      ],
      "metadata": {
        "id": "cwgF8KBiSW9k"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DwjNLCGOSadP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Feature Extraction**"
      ],
      "metadata": {
        "id": "ycHRQuysSawM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JdZvdUSOSeVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Dimensionality Reduction**"
      ],
      "metadata": {
        "id": "_ItObLM9TIEo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PriV44BITMJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Duplicates**"
      ],
      "metadata": {
        "id": "AtCKNZDHSes3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x6mgsrUUSg7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ensemble Methods**"
      ],
      "metadata": {
        "id": "gWR-0UqFVlLd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bagging , Boosting , Stacking , Voting"
      ],
      "metadata": {
        "id": "L6XI4Jo0V0WQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Draft**"
      ],
      "metadata": {
        "id": "5-iUGK35WaMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Bagging: Random Forest\n",
        "# rf = Pipeline(steps=[(\"preprocessor\", preprocessor),\n",
        "#                      (\"classifier\", RandomForestClassifier(n_estimators=200, random_state=42))])\n",
        "\n",
        "# # Boosting: Gradient Boosting\n",
        "# gb = Pipeline(steps=[(\"preprocessor\", preprocessor),\n",
        "#                      (\"classifier\", GradientBoostingClassifier(n_estimators=200, random_state=42))])\n",
        "\n",
        "# # Boosting: AdaBoost\n",
        "# ab = Pipeline(steps=[(\"preprocessor\", preprocessor),\n",
        "#                      (\"classifier\", AdaBoostClassifier(n_estimators=200, random_state=42))])\n",
        "\n",
        "# # Voting Ensemble (Hard Voting)\n",
        "# voting = VotingClassifier(\n",
        "#     estimators=[(\"rf\", RandomForestClassifier(random_state=42)),\n",
        "#                 (\"gb\", GradientBoostingClassifier(random_state=42)),\n",
        "#                 (\"lr\", LogisticRegression(max_iter=1000))],\n",
        "#     voting=\"hard\"\n",
        "# )\n",
        "\n",
        "# # Stacking Ensemble\n",
        "# stacking = StackingClassifier(\n",
        "#     estimators=[(\"rf\", RandomForestClassifier(random_state=42)),\n",
        "#                 (\"gb\", GradientBoostingClassifier(random_state=42))],\n",
        "#     final_estimator=LogisticRegression(max_iter=1000)\n",
        "# )"
      ],
      "metadata": {
        "id": "TnqX8lseVqba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KuUE46u6UZuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Spliting**"
      ],
      "metadata": {
        "id": "8D8uklJMTyC6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cZxFLGFLT0Xe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Scaling**"
      ],
      "metadata": {
        "id": "jA6DWkP4T1G-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RWd4W6EyT3Ra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Encoding**"
      ],
      "metadata": {
        "id": "hk9rKNGZT3uM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N5ciypa4T6K8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Feature Engineering After Encoding ?**"
      ],
      "metadata": {
        "id": "qqzSLSsBT-Wn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cWtRsIj1UEzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Feature Selection / Correlation**"
      ],
      "metadata": {
        "id": "cOg1ttXzUFGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wAn-kZzMUM1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Best Case**"
      ],
      "metadata": {
        "id": "xXEhPhMpUPr-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vA1w06ziUSDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Models**"
      ],
      "metadata": {
        "id": "PV2r1n6DUSa3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    \"\"\"\n",
        "    Best _ : -\n",
        "    Best Parameters: { }\n",
        "    Train Accuracy: _\n",
        "    Test Accuracy: _\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "1tnoZj2kWklG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Regularization**"
      ],
      "metadata": {
        "id": "KX83aNYIVYl6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bc_MCcP2Vbeh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}